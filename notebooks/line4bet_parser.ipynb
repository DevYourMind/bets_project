{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import datetime as dt\n",
    "from selenium.common.exceptions import StaleElementReferenceException, WebDriverException\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://line4bet.ru/1x-13-03-2023-football/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "assert 'Движение линий' in driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Теннис\" button searching\n",
    "tennis_btn = driver.find_elements(By.ID, 'tennis_btn')\n",
    "assert len(tennis_btn) > 0\n",
    "tennis_btn[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for available date\n",
    "previous_date = dt.datetime.today() - dt.timedelta(days=1)\n",
    "prev_day = previous_date.day\n",
    "dates_objects = driver.find_elements(By.XPATH, \"//td[@Data-handler]\")\n",
    "try:\n",
    "    dates_objects[prev_day-1].click()\n",
    "except:\n",
    "    dates_objects = driver.find_elements(By.XPATH, \"//td[@Data-handler]\")\n",
    "    dates_objects[prev_day-1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_event(event):\n",
    "    cleaned_event = re.sub('<tbody>|<tr>|<td>|</tbody>|</tr>|</td>|<td colspan=\"2\">|\\t','', event)\n",
    "    nsymbols_data = 16\n",
    "    date = cleaned_event[:nsymbols_data]\n",
    "    cleaned_event_ = cleaned_event[nsymbols_data:].strip()\n",
    "    splitted_event = cleaned_event_.split(';')\n",
    "    players = splitted_event[0]\n",
    "    cleaned_event_ = splitted_event[1].strip()\n",
    "    if 'Победа' in cleaned_event:\n",
    "        winner = cleaned_event_.split(', ')[1].split(',')[0].strip()\n",
    "        splitted_event = cleaned_event_.split(', ')[0].split('  ')\n",
    "        event_ = ' '.join(splitted_event[1:3])\n",
    "        score = splitted_event[-1]\n",
    "    else:\n",
    "        winner = ''\n",
    "        event_ = ' '.join(cleaned_event_.split('  ')[1:3])\n",
    "        score = ''\n",
    "    return date, event_, players, winner, score\n",
    "\n",
    "\n",
    "def get_data_table(tables):\n",
    "    page_tables = []\n",
    "    for str_table in tables:\n",
    "        soup = BeautifulSoup(str_table, 'html.parser')\n",
    "        cleaned_table_data = [\n",
    "            re.sub('<tr> | </tr>| class=\"c1\"| class=\"c2\"', '', str(x)) for x in soup.find_all('tr')[1:-1]\n",
    "        ]\n",
    "        columns = soup.find_all('th')\n",
    "        columns = [re.sub('<th> | </th>', '', str(x)) for x in columns]\n",
    "        table = []\n",
    "        for str_ in cleaned_table_data: \n",
    "            soup_str = BeautifulSoup(str_, 'html.parser')\n",
    "            table.append([x.text for x in soup_str.find_all('td')])\n",
    "        table = pd.DataFrame(data=table, columns=columns)\n",
    "        page_tables.append(table)\n",
    "    return page_tables\n",
    "\n",
    "\n",
    "def restart_page(driver):\n",
    "    tennis_btn = driver.find_elements(By.ID, 'tennis_btn')\n",
    "    tennis_btn[0].click()\n",
    "    # looking for available date\n",
    "    previous_date = dt.datetime.today() - dt.timedelta(days=1)\n",
    "    prev_day = previous_date.day\n",
    "    dates_objects = driver.find_elements(By.XPATH, \"//td[@Data-handler]\")\n",
    "    try:\n",
    "        dates_objects[prev_day-1].click()\n",
    "    except:\n",
    "        dates_objects = driver.find_elements(By.XPATH, \"//td[@Data-handler]\")\n",
    "        dates_objects[prev_day-1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcs = ['tab_1x', 'tab_bc', 'tab_fb', 'tab_mf']\n",
    "data_events = {bc: [] for bc in bcs}\n",
    "data_tables = {bc: [] for bc in bcs}\n",
    "for bc in bcs:\n",
    "    sleep(1)\n",
    "    driver.find_elements(By.ID, bc)[0].click()\n",
    "    sleep(1)\n",
    "    npages = driver.find_elements(By.CLASS_NAME, 'pages')\n",
    "    # pages iterating\n",
    "    for i in range(len(npages)):\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", npages[i])\n",
    "        except (StaleElementReferenceException, WebDriverException):\n",
    "            npages = driver.find_elements(By.CLASS_NAME, 'pages')\n",
    "            driver.execute_script(\"arguments[0].click();\", npages[i])    \n",
    "        sleep(1)\n",
    "        html_source_code = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "        html_soup = BeautifulSoup(html_source_code, 'html.parser')\n",
    "        tbody_data = np.array([str(x) for x in html_soup.find_all([\"tbody\"])], dtype='object')\n",
    "        # events parsing\n",
    "        events_indexes = ['<tbody><tr><td>' in x and 'colspan=\"2\"' in x for x in tbody_data]\n",
    "        events = tbody_data[events_indexes]\n",
    "        # data_events.append([get_data_event(x) for x in events])\n",
    "        data_events[bc].append([get_data_event(x) for x in events])\n",
    "        # tables parsing\n",
    "        tables = tbody_data[['Дата-время скана линии' in x for x in tbody_data]]\n",
    "        # data_tables.append(get_data_table(tables))\n",
    "        data_tables[bc].append(get_data_table(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(data_events['tab_1x']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimaz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(np.array(data_tables['tab_1x'], dtype='object')).size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct -> 50, 55, 42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
